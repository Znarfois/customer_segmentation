{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"sections\"></a></p>\n",
    "\n",
    "\n",
    "# Sections\n",
    "\n",
    "- <a href=\"#DS\">Data Structure</a><br>\n",
    "- <a href=\"#DM\">Data Manipulation</a><br>\n",
    "- <a href=\"#grouping\">Grouping and aggregration</a><br>\n",
    "- <a href=\"#miss\">Handling Missing Data</a><br>\n",
    "- <a href=\"#extra\">Miscellaneous</a><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "### Data Structure\n",
    "\n",
    "- Pandas is a Python package built on top of NumPy.  It is useful for special array handling, data manipulation, plotting, and web scraping.  \n",
    "\n",
    "- There are four new data structure objects in Pandas: Series, DataFrame, Time Series and Panel. The first two will be discussed.\n",
    "\n",
    "- The *DataFrame* object borrows its name from the R object.\n",
    "\n",
    "- Pandas is particularly strong in the area of handling spreadsheet structures, dealing with missing data, and processing time series data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the new data types introduced by pandas:\n",
    "\n",
    "- **Series**: 1D labeled homogeneously-typed array.\n",
    "- **DataFrame**: General 2D labeled, size-mutable tabular structure with potentially heterogeneously-typed columns.\n",
    "- **Time Series**: Series with index containing datetimes.\n",
    "- **Panel**: General 3D labeled, also size-mutable array.\n",
    "\n",
    "Import the package, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T06:09:01.643335Z",
     "start_time": "2020-09-03T06:09:00.978198Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Series\n",
    "\n",
    "- A series is a one-dimensional array-like object containing homogenously typed elements.   \n",
    "- Each element has an associated data label, called its index. By default, the index consists of ordinary array indices, i.e. consecutive integers starting from zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series(['a', 'b', 'c', 'd'])\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.index  #this is the default index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- An entry can be retrieved using the index, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Often it will be more desirable to create a series with a custom index. \n",
    "- Here the index is manually set the index from 1 to 4, with 4 repeated. Note there are two rows with the same index 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2 = pd.Series(['a', 'b', 'c', 'd','e'], index=[1, 2, 3, 4, 4])\n",
    "obj2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calling that entry gives both values.  In this way a series is different from a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2.index #custom index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The index value may also be a string.  A new entry with a string index is written:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2['something']=660\n",
    "obj2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note the entries are not retrievable by their place but the value of their index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The attribute `values` returns all the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2.values[1]   # obj.values is simply an array "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame\n",
    "\n",
    "- A data frame represents a tabular, spreadsheet-like data structure containing an ordered collection of columns.\n",
    "- Each column can be a different type (integers, strings, floating point numbers, Python objects, etc.).  \n",
    "- All columns must be the same length, to give the data frame a defined shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:33:29.723382Z",
     "start_time": "2020-09-03T04:33:29.712812Z"
    }
   },
   "outputs": [],
   "source": [
    "data = {'commodity': ['Gold', 'Gold', 'Silver', 'Silver'],\n",
    "        'year': [2013, 2014, 2014, 2015],\n",
    "        'production_Moz': [900, 109.7, 868.3, 886.7]} #world wide in million oz\n",
    "\n",
    "# convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index #standard index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index=([4,5,6,7])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index #custom integer index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The index may be set using the method `set_index`, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.set_index('commodity')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index #custom string index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#floats can also be an index\n",
    "df.set_index('production_Moz').index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] #this yields a pandas series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['year']] #this yields a pandas data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dataframe can restore the original index using the mathod `reset_index`, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A data frame can also be created with a nested list. The two ways are equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2=pd.DataFrame([[107.6, 'Gold', 2013],\n",
    "                   [109.7, 'Gold', 2014],\n",
    "                   [868.3, 'Silver', 2014],\n",
    "                   [886.7, 'Silver', 2015]], \n",
    "                    columns=['production_Moz','commodity','year'])\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A data frame has an attribute **values**, which is of the multidimensional array type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.values)\n",
    "print('-'*55)\n",
    "print(df_2.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data frame v.s. series is similar to 2D array v.s. 1D array. A data frame has column names for the added dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)  # column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each column in a DataFrame can be retrieved as a Series. \n",
    "- There are two ways to get the column: to retrieve by attribute and to retrieve by dictionary-like notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.year         # retrieve by attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year']  # retrieve by dictionary-like notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The name of an individual column may be changed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=['commodity', 'com','production']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace('com','metal')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Indexing a pandas data frame is similar to indexing a numpy array. In pandas the first index retrieves a column and the second index retrieves the row.  \n",
    "- To return the third element of the metal column, use the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['metal'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Slicing a pandas data frame is also similar to slicing a numpy array.  The following code returns the second and third elements of the production column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['production'][1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In order to slice multiple columns pass a list of column names.  The following represents the world production of gold and silver in 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['metal','production']][1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation in Pandas\n",
    "\n",
    "- Like numpy, pandas defines many broadcast operations, as well as numerous methods of manipulating data.\n",
    "\n",
    "\n",
    "### concat\n",
    "Pandas DataFrames can be expanded in both directions. First create two data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:34:32.120147Z",
     "start_time": "2020-09-03T04:34:32.110085Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.arange(9).reshape((3, 3)), \n",
    "                   columns=['a', 'b', 'c'],\n",
    "                   index=['one', 'two', 'three'])\n",
    "df2 = pd.DataFrame(np.arange(6).reshape((3, 2)), \n",
    "                   columns=['d','e'],\n",
    "                   index=['three', 'two','one'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:34:35.728758Z",
     "start_time": "2020-09-03T04:34:35.721465Z"
    }
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since the two data frames have the same number of rows, it is natural to combine them \"horizontally\".  \n",
    "- Note the concatenation takes place on the name of the index and not the order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:34:57.396719Z",
     "start_time": "2020-09-03T04:34:57.387492Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The argument \"axis = 1\" means expanding along the column indices. Setting \"axis = 0\" will combine two data frames with same number of columns vertically. \n",
    "\n",
    "- Now changing the name of row 'one' to One' gives it a different index.  In this case the concatenation will use all the rows, filling in missing values with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:32:03.778385Z",
     "start_time": "2020-09-03T04:32:03.763483Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.arange(9).reshape((3, 3)), \n",
    "                   columns=['a', 'b', 'c'],\n",
    "                   index=['One', 'two', 'three'])\n",
    "df2 = pd.DataFrame(np.arange(6).reshape((3, 2)), \n",
    "                   columns=['d','e'],\n",
    "                   index=['three', 'two','one'])\n",
    "print(df1,'\\n\\n',df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To include only the shared rows, set the join parameter to 'inner', as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis = 1, join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort\n",
    "- It is possible to order the rows of data frames using `sort_values()`.  This object method takes a column name as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:33:36.350919Z",
     "start_time": "2020-09-03T04:33:36.341131Z"
    }
   },
   "outputs": [],
   "source": [
    "df.sort_values('production_Moz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:34:08.464744Z",
     "start_time": "2020-09-03T04:34:08.456972Z"
    }
   },
   "outputs": [],
   "source": [
    "df.sort_values('production_Moz', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge\n",
    "Merging is the most common way to combine multiple data frames. Create two data frames first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:34:19.958816Z",
     "start_time": "2020-09-03T04:34:19.948421Z"
    }
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame([['a','b','c'],['d','e','f'],['g','h','i']]\\\n",
    "                   ,columns=['col1','col2','col3'])\n",
    "df4 = pd.DataFrame({'col2':['x','e','b','z'],'col4':[1,2,3,4],'col5':['i','f','e','h']})\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:35:07.078550Z",
     "start_time": "2020-09-03T04:35:07.070663Z"
    }
   },
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Merging will use the **`on`** column as a key for the merge.  The code below identifies the column ‘col2’ from both data frames. \n",
    "- The argument **`how`** set to 'inner' makes the merge only keep rows occuring in both data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:35:16.543895Z",
     "start_time": "2020-09-03T04:35:16.528720Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(df3, df4, how='inner', on ='col2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The default value of the parameter `how` is 'inner'. The following code performs the same task as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:35:18.676220Z",
     "start_time": "2020-09-03T04:35:18.664644Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(df3, df4, on ='col2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To keep every row in df1 then set the parameter `how` = 'left'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:35:21.045107Z",
     "start_time": "2020-09-03T04:35:21.032878Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(df3, df4, how='left', on ='col2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To keep all rows from both df1 and df2, set the parameter `how` = 'outer'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:35:23.247316Z",
     "start_time": "2020-09-03T04:35:23.234340Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(df3, df4, how='outer', on ='col2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the `on` column does not have the same name in the two data frames, use 'left_on' and 'right_on' to indicate how to perform the merge.  \n",
    "- Note that columns with the same name, in the two data frames, will be named with an x or y character appended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:35:26.951030Z",
     "start_time": "2020-09-03T04:35:26.939960Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(df3, df4, left_on='col2', right_on='col5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### selection and filter\n",
    "\n",
    "- The `loc` method provides purely label (index/columns)-based indexing. \n",
    "- This method allows selection from a data frame by index and columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:36:32.172335Z",
     "start_time": "2020-09-03T04:36:32.164848Z"
    }
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following returns a single column of df1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:36:35.520497Z",
     "start_time": "2020-09-03T04:36:35.514963Z"
    }
   },
   "outputs": [],
   "source": [
    "df1['a'] #gives series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[1] #this throws an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:36:45.435324Z",
     "start_time": "2020-09-03T04:36:45.431536Z"
    }
   },
   "outputs": [],
   "source": [
    "type(df1['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:36:47.172053Z",
     "start_time": "2020-09-03T04:36:47.164074Z"
    }
   },
   "outputs": [],
   "source": [
    "df1[['a']] #gives a single column data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:36:49.614152Z",
     "start_time": "2020-09-03T04:36:49.605829Z"
    }
   },
   "outputs": [],
   "source": [
    "df1[['a','c']] #gives a multi column data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following uses `loc` to return a single row of df1, using the index string name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:36:52.392189Z",
     "start_time": "2020-09-03T04:36:52.386188Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.loc['two'] # the row that has index two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:37:15.329065Z",
     "start_time": "2020-09-03T04:37:15.320795Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.loc[['two']] # the row that has index two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A second parameter is passed to loc to specify the chosen column. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:37:23.321816Z",
     "start_time": "2020-09-03T04:37:23.317052Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.loc['two', 'b'] # the row that has index two and column b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note the two ways to accomplish this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:37:27.329395Z",
     "start_time": "2020-09-03T04:37:27.324968Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df1.loc['two', 'b'])\n",
    "print(df1['b'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fancy indexing can be done with `loc` in pandas, as was done in Numpy. Select a row with a condition, as follows. \n",
    "- The code below returns all columns for the rows in which column 'a' is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:37:42.998831Z",
     "start_time": "2020-09-03T04:37:42.991479Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.loc[df1.a==0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Columns are selected in a similar way.  The code below returns all rows for the columns in which row 'one' is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:38:05.115603Z",
     "start_time": "2020-09-03T04:38:05.107119Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.loc[:, df1.loc['one']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To select data by position number, use iloc. The iloc method provides a purely position based indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:38:19.180072Z",
     "start_time": "2020-09-03T04:38:19.175228Z"
    }
   },
   "outputs": [],
   "source": [
    "# select as a matrix \n",
    "# row 2, col 3\n",
    "df1.iloc[1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:38:21.149332Z",
     "start_time": "2020-09-03T04:38:21.143972Z"
    }
   },
   "outputs": [],
   "source": [
    "# first row, first two columns\n",
    "# return a Series\n",
    "row1 = df1.iloc[0,:2]\n",
    "row1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can also use a list to slice the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:38:25.205896Z",
     "start_time": "2020-09-03T04:38:25.197906Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.iloc[[0,2], :2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DataFrame’s apply method applies a function on 1D arrays to each column or row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:38:37.171204Z",
     "start_time": "2020-09-03T04:38:37.158661Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.apply(lambda x: max(x), axis=0) # 0 stands for apply to each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:38:58.056854Z",
     "start_time": "2020-09-03T04:38:58.050600Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.apply(lambda x: min(x), axis=1) # 1 stands for apply to each row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If you just want to apply the function a single column, you can extract that specific series first and then call the `map()` method just like the `map` operator in Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:39:04.849988Z",
     "start_time": "2020-09-03T04:39:04.843440Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.a.map(lambda x: x+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:39:13.388188Z",
     "start_time": "2020-09-03T04:39:13.380687Z"
    }
   },
   "outputs": [],
   "source": [
    "#this removes row 'two'\n",
    "df1.loc[df1.index != 'two']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:39:16.024648Z",
     "start_time": "2020-09-03T04:39:16.017437Z"
    }
   },
   "outputs": [],
   "source": [
    "#this removes column 'a'\n",
    "df1.drop('a', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rows and columns may also be removed using fancy indexing or `drop()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this removes column b\n",
    "df1.loc[:,df1.columns != 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember the following expression is a boolean and acts as a mask\n",
    "df1.columns != 'b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this removes column 'b'\n",
    "df1.drop('b', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Handling Missing Data\n",
    "\n",
    "- Missing or, equivalently, corrupt data is an unavoidable reality in processing large data sets.  There are various ways of dealing with it, depending upon the circumstances:\n",
    " - Discard it, and all related data.\n",
    " - Interpolate values from surrounding data\n",
    " - Isolate it and analyze it separately\n",
    "\n",
    "- Which approach to use is a scientific question.  Whatever approach is chosen, pandas has computational methods to carry it out.\n",
    "- Read a csv file that contains NaNs. **Note:** index_col is set to 0.  This means the first column is used as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:42:45.065966Z",
     "start_time": "2020-09-03T04:42:45.037298Z"
    }
   },
   "outputs": [],
   "source": [
    "df_miss = pd.read_csv('D_missing.csv',index_col=0)\n",
    "df_miss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- To figure out where the missing data is, use the `isnull()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:42:49.974486Z",
     "start_time": "2020-09-03T04:42:49.964291Z"
    }
   },
   "outputs": [],
   "source": [
    "df_miss.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many missing values are there in the dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:42:54.359651Z",
     "start_time": "2020-09-03T04:42:54.350807Z"
    }
   },
   "outputs": [],
   "source": [
    "sum(df_miss.isnull()) # Built-in sum doesn't work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Summing up the boolean array reports how many missing values are in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:43:00.211999Z",
     "start_time": "2020-09-03T04:43:00.206175Z"
    }
   },
   "outputs": [],
   "source": [
    "np.sum(df_miss.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The same is possible for rows by setting the axis parameter to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:43:07.890330Z",
     "start_time": "2020-09-03T04:43:07.884363Z"
    }
   },
   "outputs": [],
   "source": [
    "np.sum(df_miss.isnull(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To isolate the rows in which there are null values, aggregate the `df.isnull()` boolean data frame along rows, using `any` with `axis=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:43:22.182280Z",
     "start_time": "2020-09-03T04:43:22.177311Z"
    }
   },
   "outputs": [],
   "source": [
    "mask=df_miss.isnull().any(axis=1)\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Passing the boolean Series to the first position of the `loc` method of the DataFrame selects the rows that have value equal to True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:43:45.955737Z",
     "start_time": "2020-09-03T04:43:45.944968Z"
    }
   },
   "outputs": [],
   "source": [
    "df_miss.loc[mask,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Similarly, if you want to locate the rows that contains only missing values, you can use `all()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:44:10.700427Z",
     "start_time": "2020-09-03T04:44:10.694453Z"
    }
   },
   "outputs": [],
   "source": [
    "mask=df_miss.isnull().all(axis=1)\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dropna\n",
    "- One option is to discard the rows with missing values. Below the arguments `axis=0` and `how='any'` indicate dropping *rows* with a NaN in *any* position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:45:26.088388Z",
     "start_time": "2020-09-03T04:45:26.080062Z"
    }
   },
   "outputs": [],
   "source": [
    "df_miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:45:29.591754Z",
     "start_time": "2020-09-03T04:45:29.581119Z"
    }
   },
   "outputs": [],
   "source": [
    "df_miss.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Another option is to drop rows full of NaNs. This can be done with `how='all'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:45:32.206284Z",
     "start_time": "2020-09-03T04:45:32.195244Z"
    }
   },
   "outputs": [],
   "source": [
    "df_miss.dropna(axis=0, how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Applying `dropna()` to the above data frame may be done once more. Drop a column with the argument `axis=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:45:49.988313Z",
     "start_time": "2020-09-03T04:45:49.977790Z"
    }
   },
   "outputs": [],
   "source": [
    "df_miss.dropna(axis=0, how='all').dropna(axis=1, how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fillna\n",
    "\n",
    "- An alternative to discarding information is to **impute** the data. \n",
    "- This can be done with the `fillna()` function with the value to be imputed as the argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_miss.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Another common way to impute is by the mean of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_miss['one'].fillna(df_miss['one'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolate\n",
    "\n",
    "- Interpolation is the insertion of new data between preeexisting fixed points. Linear interpolation uses a linear function to create new data point.  \n",
    "- In pandas this is accomplished using `interpolate()` with the `method` parameter set to linear, `method='linear'`.  \n",
    "- This will fill in missing data points with a linear interpolation between the data points bordering the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:46:11.404582Z",
     "start_time": "2020-09-03T04:46:11.395459Z"
    }
   },
   "outputs": [],
   "source": [
    "df_miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:46:22.997551Z",
     "start_time": "2020-09-03T04:46:22.985185Z"
    }
   },
   "outputs": [],
   "source": [
    "df_miss.interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since `df.loc['b','one']` is a NaN between `df.loc['a','one']` and `df.loc['c','one']`, the value inserted is the mean of them.\n",
    "- Note how this technique treats NaN values at the bottom of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:46:26.052479Z",
     "start_time": "2020-09-03T04:46:26.047521Z"
    }
   },
   "outputs": [],
   "source": [
    "(df_miss.loc['a', 'one'] + df_miss.loc['c', 'one'])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"grouping\"></a></p>\n",
    "\n",
    "# Grouping and Aggregation\n",
    "\n",
    "Grouping and  aggregation are critical components of data analysis which involve:\n",
    "\n",
    "- **Splitting** data into groups based on some features.\n",
    "- **Applying** a function to each group independently.\n",
    "- **Combining** the result into data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping\n",
    "\n",
    "Grouping splits a data frame into categorical groups, according to a given variable, or set of variables.   Consider the following data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T06:09:13.212681Z",
     "start_time": "2020-09-03T06:09:13.184057Z"
    }
   },
   "outputs": [],
   "source": [
    "Country = pd.read_csv('D_countries.csv',delimiter=';')\n",
    "Country.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T06:09:32.842748Z",
     "start_time": "2020-09-03T06:09:32.808123Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#choose the desires columns\n",
    "Country=Country[['Country','Continent','Population','Area','Coastline',\n",
    "                'Currency','Birthrate','Deathrate','Life expectancy']]\n",
    "#change the column names to lowercase\n",
    "Country.columns = Country.columns.str.lower()\n",
    "#drop columns with missing values (Antarctica)\n",
    "Country=Country.dropna(axis=0, how='any')\n",
    "#limit to countries with populations over 20 million\n",
    "Country=Country[Country['population']>20e6]\n",
    "#add a boolean valued column that is true for countries with coastlines\n",
    "Country['coastal']=Country['coastline']!=0\n",
    "Country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This will calculate the mean, min, max population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:49:37.077489Z",
     "start_time": "2020-09-03T04:49:37.072292Z"
    }
   },
   "outputs": [],
   "source": [
    "Country['population'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:49:42.316762Z",
     "start_time": "2020-09-03T04:49:42.312675Z"
    }
   },
   "outputs": [],
   "source": [
    "Country['population'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Country['population'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This will calculate the sum of all populations in Asia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:49:53.056075Z",
     "start_time": "2020-09-03T04:49:53.048714Z"
    }
   },
   "outputs": [],
   "source": [
    "Country[Country['continent']=='Asia']['population'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This will return the number of land-locked countries in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:49:58.091566Z",
     "start_time": "2020-09-03T04:49:58.085843Z"
    }
   },
   "outputs": [],
   "source": [
    "Country[Country['coastal']==False].country.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To group the countries by continent, do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:50:02.862421Z",
     "start_time": "2020-09-03T04:50:02.859008Z"
    }
   },
   "outputs": [],
   "source": [
    "group = Country.groupby('continent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `group` is assigned the value returned by the `groupby` function, whose type is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:50:05.415148Z",
     "start_time": "2020-09-03T04:50:05.412014Z"
    }
   },
   "outputs": [],
   "source": [
    "print(type(group))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `DataFrameGroupBy` object is an `iterable`. Iterate over the object and print the contents, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:50:07.684778Z",
     "start_time": "2020-09-03T04:50:07.651589Z"
    }
   },
   "outputs": [],
   "source": [
    "for item in group:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each `item` we print is a two element `tuple`. The first element is the grouping.  \n",
    "- The second element is a data frame for that grouping. There is an alternative way of iterating through the groupby object, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:50:14.100745Z",
     "start_time": "2020-09-03T04:50:14.064894Z"
    }
   },
   "outputs": [],
   "source": [
    "for key, values in group:\n",
    "    print(key) #this indicates the grouping\n",
    "    print('-'*70)\n",
    "    print(values) #this is a dataframe for that \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is a great way to print and inspect a `DataFrameGroupBy` object. Above was an example of **splitting**.\n",
    "- The size function includes the number of elements in each grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:50:28.529469Z",
     "start_time": "2020-09-03T04:50:28.524197Z"
    }
   },
   "outputs": [],
   "source": [
    "group.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following will return a data frame with the mean values for every coulumn in every grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:50:30.650328Z",
     "start_time": "2020-09-03T04:50:30.635333Z"
    }
   },
   "outputs": [],
   "source": [
    "group.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If you just want the mean of one specific column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:50:34.310002Z",
     "start_time": "2020-09-03T04:50:34.302845Z"
    }
   },
   "outputs": [],
   "source": [
    "group.birthrate.mean()\n",
    "# group[['birthrate']].mean() # This returns a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The data frame can be grouped by multiple keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:50:37.017933Z",
     "start_time": "2020-09-03T04:50:37.014905Z"
    }
   },
   "outputs": [],
   "source": [
    "group2 = Country.groupby(['continent', 'currency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:50:39.633227Z",
     "start_time": "2020-09-03T04:50:39.476334Z"
    }
   },
   "outputs": [],
   "source": [
    "for key, values in group2:\n",
    "    print(key)\n",
    "    print('-'*70)\n",
    "    print(values)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:50:47.879280Z",
     "start_time": "2020-09-03T04:50:47.853356Z"
    }
   },
   "outputs": [],
   "source": [
    "group2.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply multiple functions to each group with the method `agg()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:50:54.705216Z",
     "start_time": "2020-09-03T04:50:54.625741Z"
    }
   },
   "outputs": [],
   "source": [
    "group.agg(['count', 'sum', 'min', 'max', 'mean', 'std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To look at a single column of the aggregate analysis, use the column indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:50:57.820358Z",
     "start_time": "2020-09-03T04:50:57.765070Z"
    }
   },
   "outputs": [],
   "source": [
    "group.agg(['count', 'sum', 'min', 'max', 'mean', 'std'])['birthrate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The column std is missing a value above because Australia only has one row in the data frame.\n",
    "- Also note that `sum` is an inappropriate function to apply to birthrate where it would be applicable to population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Different aggregating functions can be applied to different columns. This can be done with a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:51:03.428984Z",
     "start_time": "2020-09-03T04:51:03.369447Z"
    }
   },
   "outputs": [],
   "source": [
    "colFun = {'country':['count'],\n",
    "          'population': ['sum','min', 'max','mean','std'], \n",
    "          'area': ['sum','min', 'max','mean'],\n",
    "          'coastline':['sum','min', 'max'],\n",
    "          'birthrate':['min', 'max','mean','std'],\n",
    "          'deathrate':['min', 'max','mean','std'],\n",
    "          'life expectancy':['min', 'max','mean','std']}\n",
    "analysis=group.agg(colFun)\n",
    "analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Custom aggregation functions may also be applied. In the previous examples, aggregation functions are applied to each **column** in a data frame. \n",
    "- Keep this in mind when defining a custom function. For example, build a function that computes the mean after removing maxima (truncated mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:51:08.853987Z",
     "start_time": "2020-09-03T04:51:08.850576Z"
    }
   },
   "outputs": [],
   "source": [
    "def trunc_mean(x):    # x has to be a 'vector' (1d array or pandas Series)\n",
    "    sec=x[x!=x.max()]\n",
    "    if sec.shape[0]!=0:\n",
    "        return np.mean(sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T04:51:29.458461Z",
     "start_time": "2020-09-03T04:51:29.406178Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Country[Country['country']!='Australia' ].groupby('continent').agg(trunc_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unique and nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T06:09:37.874367Z",
     "start_time": "2020-09-03T06:09:37.869703Z"
    }
   },
   "outputs": [],
   "source": [
    "Country['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T06:09:49.364880Z",
     "start_time": "2020-09-03T06:09:49.359545Z"
    }
   },
   "outputs": [],
   "source": [
    "Country['country'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T05:46:06.342371Z",
     "start_time": "2020-09-03T05:46:06.118407Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "corr = Country.corr()\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T05:53:04.067906Z",
     "start_time": "2020-09-03T05:53:03.901013Z"
    }
   },
   "outputs": [],
   "source": [
    "Country.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T05:53:48.218779Z",
     "start_time": "2020-09-03T05:53:48.216552Z"
    }
   },
   "source": [
    "### histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T05:58:44.034674Z",
     "start_time": "2020-09-03T05:58:43.315839Z"
    }
   },
   "outputs": [],
   "source": [
    "Country[['area', 'population', 'coastline', 'birthrate', 'deathrate', 'life expectancy']].hist()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
